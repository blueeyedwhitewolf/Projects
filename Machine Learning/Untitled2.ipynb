{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'util'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6d06629a0064>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneuralnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mneuralnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimg_as_float\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'util'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import Iterator,load_img\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from util.neuralnet import neuralnet\n",
    "from skimage import img_as_float\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ValIterator(Iterator):\n",
    "    \"\"\"Class to iterate A and B images at the same time.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "                 self, \n",
    "                 dir_dataset, \n",
    "                 csv_v_filename_prefix = \"Fovea_locations_v.csv\", \n",
    "                 dir_Validation =\"Validation\", \n",
    "                 dir_Glaucoma = \"Glaucoma\",\n",
    "                 dir_NonGlaucoma = \"Non-Glaucoma\",\n",
    "                 target_size=(150,150),\n",
    "                 batch_size=32, \n",
    "                 shuffle=True, \n",
    "                 seed = None\n",
    "                ):\n",
    "        \n",
    "        self.target_size=target_size\n",
    "        \n",
    "        # Carrega nome ficheiros das imagens de retina\n",
    "        ## Validation\n",
    "        self.path_Validation = os.path.join(dir_dataset, dir_Validation)\n",
    "        \n",
    "        self.ficheiros_Validation = set(x for x in os.listdir(self.path_Validation))\n",
    "        print (\"Numero de ficheiros Validation:\", len(self.ficheiros_Validation))\n",
    "        \n",
    "        self.n=len(self.ficheiros_Validation)\n",
    "            \n",
    "        self.a_fnames = sorted(os.listdir(self.path_Validation))\n",
    "        \n",
    "        self.filenames=list(self.ficheiros_Validation)\n",
    "\n",
    "        # Carega ficheiro CSV com posicao da Fove\n",
    "        ## Validation\n",
    "        \n",
    "        path_csv_v = os.path.join(dir_dataset, csv_v_filename_prefix)\n",
    "\n",
    "        self.data_Validation = pd.read_csv(path_csv_v)\n",
    "        \n",
    "        self.Fovea_X_Validation=self.data_Validation.iloc[:,3]\n",
    "        self.Fovea_Y_Validation=self.data_Validation.iloc[:,4]\n",
    "        \n",
    "        self.img_shape_a = self._get_img_shape(self.target_size, 1)\n",
    "        self.img_shape_b = self._get_img_shape(self.target_size, 1)\n",
    "        \n",
    "        \n",
    "        super(ValIterator, self).__init__(len(self.a_fnames), batch_size,\n",
    "                                               shuffle, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(self, idx):\n",
    "        \"\"\"Get a pair of images with index idx.\"\"\"\n",
    "        a_fname = self.filenames[idx]\n",
    "\n",
    "        a = load_img(os.path.join(self.path_Validation, a_fname),\n",
    "                     grayscale=True,\n",
    "                     target_size=self.target_size)\n",
    "        \n",
    "        a = np.array(a)\n",
    "  \n",
    "        if(len(a.shape)<3):\n",
    "            a = a.reshape(self.img_shape_a)\n",
    "\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_img_shape(self, size, ch=1):\n",
    "\n",
    "        img_shape = size + (ch,)\n",
    "    \n",
    "        return img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_mem(self):\n",
    "        \"\"\"Load images to memory.\"\"\"\n",
    "        self.a = np.zeros((self.N,) + self.img_shape_a)\n",
    "\n",
    "        for idx in range(self.N):\n",
    "            ai = self.load_imgs(idx)\n",
    "            self.a[idx] = ai  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next(self):\n",
    "        \"\"\"Get the next pair of the sequence.\"\"\"\n",
    "\n",
    "        # Lock the iterator when the index is changed.\n",
    "        with self.lock:\n",
    "            index_array = next(self.index_generator)    \n",
    "        current_batch_size = len(index_array)\n",
    "        \n",
    "        batch_a = np.zeros((current_batch_size,) + self.img_shape_a)\n",
    "        batch_b = np.zeros((current_batch_size,))\n",
    "        batch_c = np.zeros((current_batch_size,))\n",
    "\n",
    "\n",
    "        for i, j in enumerate(index_array):\n",
    "            a_img= self.load_imgs(j)\n",
    "            #if(np.max(batch_a)>1.):\n",
    "                #a_img=a_img/255.\n",
    "\n",
    "            batch_a[i] = a_img\n",
    "            batch_b[i] = self.Fovea_X_Validation[j]\n",
    "            batch_c[i] = self.Fovea_Y_Validation[j]\n",
    "        \n",
    "        batch_a=batch_a/255.\n",
    "        batch_b=batch_b-np.mean(batch_b)/np.std(batch_b)\n",
    "        batch_c=batch_c-np.mean(batch_c)/np.std(batch_c)\n",
    "        return [batch_a,batch_b,batch_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(self):\n",
    "        while 1:\n",
    "            x,y,z = self.next()\n",
    "            #print x.shape,y.shape\n",
    "            yield x,y,z\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainIterator(Iterator):\n",
    "    \"\"\"Class to iterate A and B images at the same time.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "                 self, \n",
    "                 dir_dataset, \n",
    "                 csv_t_filename_prefix = \"Fovea_locations_t.csv\", \n",
    "                 dir_Validation =\"Validation\", \n",
    "                 dir_Training = \"Training\",\n",
    "                 dir_Glaucoma = \"Glaucoma\",\n",
    "                 dir_NonGlaucoma = \"Non-Glaucoma\",\n",
    "                 target_size=(150,150),\n",
    "                 batch_size=32, \n",
    "                 shuffle=True, \n",
    "                 seed = None\n",
    "                ):\n",
    "    \n",
    "        \n",
    "        self.target_size=target_size\n",
    "        \n",
    "\n",
    "        ## Training\n",
    "        self.path_Training = os.path.join(dir_dataset, dir_Training)\n",
    "        \n",
    "        self.ficheiros_Training = set(x for x in os.listdir(self.path_Training))\n",
    "        print (\"Numero de ficheiros Training:\", len(self.ficheiros_Training))\n",
    "        \n",
    "        self.n=len(self.ficheiros_Training)\n",
    "        \n",
    "        self.a_fnames = sorted(os.listdir(self.path_Training))\n",
    "\n",
    "        self.filenames=list(self.ficheiros_Training)       \n",
    "        # Carega ficheiro CSV com posicao da Fove\n",
    "        ## Validation\n",
    "        \n",
    "        \n",
    "        ## Training\n",
    "        \n",
    "        path_csv_t = os.path.join(dir_dataset,csv_t_filename_prefix)\n",
    "\n",
    "        self.data_Training = pd.read_csv(path_csv_t)\n",
    "        \n",
    "        self.Fovea_X_Training=self.data_Training.iloc[:,2]\n",
    "        self.Fovea_Y_Training=self.data_Training.iloc[:,3]\n",
    "        \n",
    "        self.img_shape_a = self._get_img_shape(self.target_size, 1)\n",
    "        self.img_shape_b = self._get_img_shape(self.target_size, 1)\n",
    "        \n",
    "        super(TrainIterator, self).__init__(len(self.a_fnames), batch_size,\n",
    "                                               shuffle, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_img_shape(self, size, ch=1):\n",
    "\n",
    "    img_shape = size + (ch,)\n",
    "\n",
    "    return img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(self, idx):\n",
    "        \"\"\"Get a pair of images with index idx.\"\"\"\n",
    "        a_fname = self.filenames[idx]\n",
    "\n",
    "        a = load_img(os.path.join(self.path_Training, a_fname),\n",
    "                     grayscale=True,\n",
    "                     target_size=self.target_size)\n",
    "        \n",
    "        a = np.array(a)\n",
    "  \n",
    "        if(len(a.shape)<3):\n",
    "            a = a.reshape(self.img_shape_a)\n",
    "\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
